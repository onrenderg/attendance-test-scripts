<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <title>Face Verification</title>
    <script>
        // Fetch polyfill for file:// URLs - required for face-api.js model loading in Android WebView
        (function () {
            var originalFetch = window.fetch;
            window.fetch = function (input, init) {
                var url = typeof input === 'string' ? input : (input && input.url ? input.url : null);
                if (!url) return originalFetch.call(window, input, init);

                // Convert relative URLs to file:// URLs
                if (!url.startsWith('http') && !url.startsWith('file://')) {
                    var base = window.location.href.substring(0, window.location.href.lastIndexOf('/') + 1);
                    if (url.startsWith('./')) {
                        url = base + url.substring(2);
                    } else if (url.startsWith('/')) {
                        url = 'file://' + url;
                    } else {
                        url = base + url;
                    }
                }

                // Handle file:// URLs with XHR
                if (url.startsWith('file://')) {
                    return new Promise(function (resolve, reject) {
                        var xhr = new XMLHttpRequest();
                        xhr.open('GET', url, true);
                        xhr.responseType = 'arraybuffer';

                        xhr.onload = function () {
                            if (xhr.status === 0 || xhr.status === 200) {
                                var arrayBuffer = xhr.response;
                                var headers = new Headers();
                                headers.set('content-type', url.endsWith('.json') ? 'application/json' : 'application/octet-stream');

                                resolve({
                                    ok: true,
                                    status: 200,
                                    headers: headers,
                                    url: url,
                                    json: function () {
                                        var text = new TextDecoder().decode(arrayBuffer);
                                        return Promise.resolve(JSON.parse(text));
                                    },
                                    text: function () {
                                        return Promise.resolve(new TextDecoder().decode(arrayBuffer));
                                    },
                                    arrayBuffer: function () {
                                        return Promise.resolve(arrayBuffer);
                                    },
                                    blob: function () {
                                        return Promise.resolve(new Blob([arrayBuffer]));
                                    }
                                });
                            } else {
                                reject(new Error('XHR failed: ' + xhr.status + ' for ' + url));
                            }
                        };
                        xhr.onerror = function () {
                            reject(new Error('XHR error for ' + url));
                        };
                        xhr.send();
                    });
                }
                return originalFetch.call(window, input, init);
            };
        })();
    </script>
    <script src="static/js/face-api.min.js"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
            min-height: 100vh;
            color: white;
            overflow: hidden;
        }

        .container {
            width: 100%;
            height: 100vh;
            display: flex;
            flex-direction: column;
            position: relative;
        }

        /* Video container - full screen */
        .video-container {
            flex: 1;
            position: relative;
            background: #000;
            overflow: hidden;
        }

        #video {
            width: 100%;
            height: 100%;
            object-fit: cover;
        }

        /* Face overlay guide */
        .face-guide {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            width: 200px;
            height: 260px;
            border: 3px dashed rgba(255, 255, 255, 0.5);
            border-radius: 50%;
            pointer-events: none;
        }

        /* Status overlay */
        .status-overlay {
            position: absolute;
            top: 10px;
            left: 0;
            right: 0;
            text-align: center;
            z-index: 10;
        }

        .status-text {
            display: inline-block;
            padding: 10px 20px;
            background: rgba(0, 0, 0, 0.7);
            border-radius: 20px;
            font-size: 14px;
            color: #00d4ff;
        }

        .status-text.success {
            color: #4CAF50;
            background: rgba(76, 175, 80, 0.2);
        }

        .status-text.error {
            color: #f44336;
            background: rgba(244, 67, 54, 0.2);
        }

        .status-text.warning {
            color: #ffc107;
            background: rgba(255, 193, 7, 0.2);
        }

        /* Bottom controls */
        .controls {
            padding: 20px;
            background: rgba(0, 0, 0, 0.8);
            display: flex;
            flex-direction: column;
            gap: 10px;
        }

        .info-row {
            display: flex;
            justify-content: space-between;
            font-size: 12px;
            color: #888;
        }

        .capture-row {
            display: flex;
            justify-content: center;
            gap: 20px;
        }

        .btn {
            padding: 15px 30px;
            font-size: 16px;
            font-weight: 600;
            border: none;
            border-radius: 30px;
            cursor: pointer;
            transition: all 0.3s ease;
        }

        .btn-primary {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
        }

        .btn-primary:hover:not(:disabled) {
            transform: scale(1.05);
            box-shadow: 0 6px 20px rgba(102, 126, 234, 0.4);
        }

        .btn-success {
            background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%);
            color: white;
        }

        .btn-danger {
            background: linear-gradient(135deg, #f44336 0%, #ff5722 100%);
            color: white;
        }

        .btn:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }

        /* Result overlay */
        .result-overlay {
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: rgba(0, 0, 0, 0.9);
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            z-index: 100;
            display: none;
        }

        .result-overlay.show {
            display: flex;
        }

        .result-icon {
            font-size: 80px;
            margin-bottom: 20px;
        }

        .result-text {
            font-size: 24px;
            font-weight: bold;
            margin-bottom: 10px;
        }

        .result-details {
            font-size: 14px;
            color: #888;
            margin-bottom: 30px;
        }

        .result-match {
            color: #4CAF50;
        }

        .result-no-match {
            color: #f44336;
        }

        /* Hidden canvas for capture */
        #captureCanvas {
            display: none;
        }
    </style>
</head>

<body>
    <div class="container">
        <!-- Video Stream -->
        <div class="video-container">
            <video id="video" autoplay playsinline muted></video>
            <div class="face-guide"></div>

            <!-- Status Overlay -->
            <div class="status-overlay">
                <div id="statusText" class="status-text">Initializing...</div>
            </div>
        </div>

        <!-- Controls -->
        <div class="controls">
            <div class="info-row">
                <span id="candidateInfo">Candidate: Loading...</span>
                <span id="thresholdInfo">Threshold: 0.5</span>
            </div>
            <div class="capture-row">
                <button id="captureBtn" class="btn btn-primary" onclick="captureAndVerify()" disabled>
                    ðŸ“· Capture & Verify
                </button>
            </div>
        </div>

        <!-- Result Overlay -->
        <div id="resultOverlay" class="result-overlay">
            <div id="resultIcon" class="result-icon"></div>
            <div id="resultText" class="result-text"></div>
            <div id="resultDetails" class="result-details"></div>
            <button class="btn btn-primary" onclick="closeResult()">Try Again</button>
        </div>
    </div>

    <canvas id="captureCanvas"></canvas>

    <script>
        // ============================================================
        // PRE-STORED VECTORS - MANUALLY INSERT HERE DURING BUILD
        // Generated by vector.html
        // Format: { RollNo, ApplicationNo, Name, FathersName, Category, Vector }
        // ============================================================
        const STORED_CANDIDATES = [
            // Example entry (replace with actual data from vector.html):
            // {
            //     RollNo: "123456",
            //     ApplicationNo: "APP001",
            //     Name: "John Doe",
            //     FathersName: "Father Name",
            //     Category: "GEN",
            //     Vector: [0.1, -0.2, 0.3, ... 128 values]
            // }
        ];

        // ============================================================
        // CONFIGURATION
        // ============================================================
        const CONFIG = {
            MATCH_THRESHOLD: 0.5,       // Lower = stricter
            MIN_CONFIDENCE: 0.3,        // SSD model minimum confidence
            MODEL_PATH: 'static/models',
            EYE_CLOSED_THRESHOLD: 5,    // Pixels - if eye height < this, eyes are closed
            REQUIRE_BLINK: true         // Require blink for liveness check
        };

        // ============================================================
        // STATE
        // ============================================================
        let modelsLoaded = false;
        let videoStream = null;
        let currentCandidate = null;
        let lastMatchImage = null;
        let isDetecting = false;
        let detectionLoop = null;
        let lastDetectionTime = 0;
        const DETECTION_INTERVAL = 300; // ms between detections (faster for blink)

        // Blink detection state
        let blinkState = 'waiting'; // 'waiting', 'eyes_open', 'eyes_closed', 'blink_detected'
        let eyesOpenCount = 0;
        let eyesClosedCount = 0;
        let blinkVerified = false;
        let matchedResult = null; // Store match result until blink is verified

        // ============================================================
        // INITIALIZATION
        // ============================================================
        async function init() {
            updateStatus('Loading face models...', 'warning');

            try {
                // Load face-api models
                await faceapi.nets.tinyFaceDetector.loadFromUri(CONFIG.MODEL_PATH);
                await faceapi.nets.faceLandmark68Net.loadFromUri(CONFIG.MODEL_PATH);
                await faceapi.nets.faceRecognitionNet.loadFromUri(CONFIG.MODEL_PATH);
                await faceapi.nets.ssdMobilenetv1.loadFromUri(CONFIG.MODEL_PATH);

                modelsLoaded = true;
                updateStatus('Models loaded. Starting camera...', 'warning');

                // Start camera
                await startCamera();

                // Setup candidate info
                if (STORED_CANDIDATES.length > 0) {
                    currentCandidate = STORED_CANDIDATES[0];
                    document.getElementById('candidateInfo').textContent =
                        'Candidate: ' + currentCandidate.Name;
                } else {
                    document.getElementById('candidateInfo').textContent =
                        'No candidates loaded';
                }

            } catch (error) {
                updateStatus('Error: ' + error.message, 'error');
                notifyCallback('error', { message: error.message });
            }
        }

        // ============================================================
        // CAMERA FUNCTIONS
        // ============================================================
        async function startCamera() {
            const video = document.getElementById('video');

            // Try multiple camera configurations
            const constraints = [
                { video: { facingMode: 'environment', width: 320, height: 240 } },
                { video: { facingMode: 'user', width: 320, height: 240 } },
                { video: { facingMode: 'environment' } },
                { video: { facingMode: 'user' } },
                { video: true }  // Last resort - any camera
            ];

            let lastError = null;

            for (const constraint of constraints) {
                try {
                    updateStatus('Requesting camera...', 'warning');
                    videoStream = await navigator.mediaDevices.getUserMedia(constraint);
                    video.srcObject = videoStream;

                    updateStatus('Position your face in the circle', 'success');
                    document.getElementById('captureBtn').disabled = false;

                    // Start detection loop when video is ready
                    video.onloadeddata = () => startDetectionLoop();

                    // Notify C# that we're ready
                    notifyCallback('ready', { status: 'camera_started' });
                    return; // Success - exit function

                } catch (error) {
                    lastError = error;
                    console.log('Camera attempt failed:', constraint, error.message);
                }
            }

            // All attempts failed
            updateStatus('Camera error: ' + (lastError ? lastError.message : 'No camera'), 'error');
            notifyCallback('error', { message: lastError ? lastError.message : 'No camera available' });
        }

        function stopCamera() {
            stopDetectionLoop();
            if (videoStream) {
                videoStream.getTracks().forEach(track => track.stop());
                videoStream = null;
            }
        }

        // ============================================================
        // CONTINUOUS FACE DETECTION LOOP
        // ============================================================
        function startDetectionLoop() {
            if (isDetecting) return;
            isDetecting = true;
            detectFaceLoop();
        }

        function stopDetectionLoop() {
            isDetecting = false;
            if (detectionLoop) {
                cancelAnimationFrame(detectionLoop);
                detectionLoop = null;
            }
        }

        async function detectFaceLoop() {
            if (!isDetecting || !modelsLoaded) return;

            const now = Date.now();
            if (now - lastDetectionTime < DETECTION_INTERVAL) {
                detectionLoop = requestAnimationFrame(detectFaceLoop);
                return;
            }
            lastDetectionTime = now;

            try {
                const video = document.getElementById('video');
                if (video.readyState !== 4) {
                    detectionLoop = requestAnimationFrame(detectFaceLoop);
                    return;
                }

                // Use TinyFaceDetector for faster live detection
                const detection = await faceapi
                    .detectSingleFace(video, new faceapi.TinyFaceDetectorOptions())
                    .withFaceLandmarks()
                    .withFaceDescriptor();

                if (detection) {
                    // Get the live vector
                    const liveVector = Array.from(detection.descriptor);

                    // Check eye state for blink detection
                    const eyeState = detectEyesClosed(detection.landmarks);

                    // If blink is required and we have a match waiting for verification
                    if (CONFIG.REQUIRE_BLINK && matchedResult) {
                        handleBlinkVerification(eyeState);
                    } else {
                        // No match yet - try to find one
                        const result = findBestMatch(liveVector);

                        if (result.isMatch) {
                            // Capture the current frame
                            captureCurrentFrame();

                            if (CONFIG.REQUIRE_BLINK) {
                                // Store match and wait for blink
                                matchedResult = result;
                                resetBlinkState();
                                updateStatus('âœ… Match found! Please BLINK to verify', 'success');
                            } else {
                                // No blink required - show result immediately
                                stopDetectionLoop();
                                showResult(result);
                                return;
                            }
                        } else if (STORED_CANDIDATES.length > 0) {
                            updateStatus(`Looking for match... (${result.confidence}%)`, 'warning');
                        } else {
                            updateStatus('Position your face in the circle', 'success');
                        }
                    }
                } else {
                    // No face detected
                    if (matchedResult) {
                        updateStatus('Face lost! Position your face and blink', 'warning');
                    } else {
                        updateStatus('Position your face in the circle', 'success');
                    }
                    // Reset blink state if face is lost
                    resetBlinkState();
                }

            } catch (error) {
                console.error('Detection error:', error);
            }

            // Continue loop
            if (isDetecting) {
                detectionLoop = requestAnimationFrame(detectFaceLoop);
            }
        }

        // ============================================================
        // BLINK DETECTION FUNCTIONS
        // ============================================================
        function detectEyesClosed(landmarks) {
            try {
                const leftEye = landmarks.getLeftEye();
                const rightEye = landmarks.getRightEye();

                // Calculate vertical distance between upper and lower eyelid
                // Points: 1=upper, 5=lower for each eye
                const leftEyeHeight = Math.abs(leftEye[1].y - leftEye[5].y);
                const rightEyeHeight = Math.abs(rightEye[1].y - rightEye[5].y);

                const eyesClosed = (leftEyeHeight < CONFIG.EYE_CLOSED_THRESHOLD &&
                    rightEyeHeight < CONFIG.EYE_CLOSED_THRESHOLD);

                return {
                    eyesClosed: eyesClosed,
                    leftEyeHeight: leftEyeHeight,
                    rightEyeHeight: rightEyeHeight
                };
            } catch (e) {
                return { eyesClosed: false, leftEyeHeight: 10, rightEyeHeight: 10 };
            }
        }

        function handleBlinkVerification(eyeState) {
            if (eyeState.eyesClosed) {
                eyesClosedCount++;
                if (blinkState === 'eyes_open' && eyesOpenCount >= 2) {
                    // Eyes were open, now closed - potential blink
                    blinkState = 'eyes_closed';
                }
                updateStatus(`ðŸ‘ï¸ Eyes closed... (Keep blinking!)`, 'warning');
            } else {
                eyesOpenCount++;
                if (blinkState === 'eyes_closed' && eyesClosedCount >= 1) {
                    // Eyes were closed, now open - BLINK DETECTED!
                    blinkState = 'blink_detected';
                    blinkVerified = true;

                    // Blink verified - show the result
                    stopDetectionLoop();
                    showResult(matchedResult);
                    return;
                } else if (blinkState === 'waiting') {
                    blinkState = 'eyes_open';
                }
                updateStatus(`âœ… Match found! Please BLINK to verify ðŸ‘ï¸`, 'success');
            }
        }

        function resetBlinkState() {
            blinkState = 'waiting';
            eyesOpenCount = 0;
            eyesClosedCount = 0;
            blinkVerified = false;
            // Don't reset matchedResult here - only reset when no face or new match
        }

        function captureCurrentFrame() {
            const video = document.getElementById('video');
            const canvas = document.getElementById('captureCanvas');
            canvas.width = video.videoWidth || 640;
            canvas.height = video.videoHeight || 480;
            const ctx = canvas.getContext('2d');
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
            lastMatchImage = canvas.toDataURL('image/jpeg', 0.9);
        }

        // ============================================================
        // CAPTURE AND VERIFICATION
        // ============================================================
        async function captureAndVerify() {
            const captureBtn = document.getElementById('captureBtn');
            captureBtn.disabled = true;
            updateStatus('Capturing...', 'warning');

            try {
                const video = document.getElementById('video');
                const canvas = document.getElementById('captureCanvas');

                // Capture frame
                canvas.width = video.videoWidth || 640;
                canvas.height = video.videoHeight || 480;
                const ctx = canvas.getContext('2d');
                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

                // Get base64 image
                const imageBase64 = canvas.toDataURL('image/jpeg', 0.9);
                lastMatchImage = imageBase64;

                updateStatus('Detecting face...', 'warning');

                // Detect face and extract vector
                const img = new Image();
                img.src = imageBase64;
                await new Promise(resolve => { img.onload = resolve; });

                const detection = await faceapi
                    .detectSingleFace(img, new faceapi.SsdMobilenetv1Options({ minConfidence: CONFIG.MIN_CONFIDENCE }))
                    .withFaceLandmarks()
                    .withFaceDescriptor();

                if (!detection) {
                    updateStatus('No face detected. Try again.', 'error');
                    captureBtn.disabled = false;
                    return;
                }

                updateStatus('Comparing with registered face...', 'warning');

                // Compare with stored candidates
                const liveVector = Array.from(detection.descriptor);
                const result = findBestMatch(liveVector);

                // Show result
                showResult(result);

            } catch (error) {
                updateStatus('Error: ' + error.message, 'error');
                captureBtn.disabled = false;
            }
        }

        // ============================================================
        // VECTOR COMPARISON
        // ============================================================
        function euclideanDistance(v1, v2) {
            if (!v1 || !v2 || v1.length !== v2.length) return Infinity;
            return Math.sqrt(v1.reduce((sum, val, i) => sum + Math.pow(val - v2[i], 2), 0));
        }

        function findBestMatch(liveVector) {
            if (STORED_CANDIDATES.length === 0) {
                return {
                    isMatch: false,
                    name: null,
                    distance: Infinity,
                    confidence: 0,
                    message: 'No candidates registered'
                };
            }

            let bestMatch = {
                candidate: null,
                distance: Infinity
            };

            for (const candidate of STORED_CANDIDATES) {
                if (!candidate.Vector || candidate.Vector.length !== 128) continue;

                const distance = euclideanDistance(liveVector, candidate.Vector);
                if (distance < bestMatch.distance) {
                    bestMatch = { candidate, distance };
                }
            }

            const isMatch = bestMatch.distance < CONFIG.MATCH_THRESHOLD;
            const confidence = Math.max(0, Math.min(100, (1 - bestMatch.distance) * 100));

            return {
                isMatch: isMatch,
                name: bestMatch.candidate ? bestMatch.candidate.Name : null,
                rollNo: bestMatch.candidate ? bestMatch.candidate.RollNo : null,
                distance: bestMatch.distance,
                confidence: confidence.toFixed(2),
                threshold: CONFIG.MATCH_THRESHOLD
            };
        }

        // ============================================================
        // RESULT DISPLAY
        // ============================================================
        function showResult(result) {
            const overlay = document.getElementById('resultOverlay');
            const icon = document.getElementById('resultIcon');
            const text = document.getElementById('resultText');
            const details = document.getElementById('resultDetails');

            if (result.isMatch) {
                icon.textContent = 'âœ…';
                icon.className = 'result-icon result-match';
                text.textContent = 'MATCH FOUND!';
                text.className = 'result-text result-match';
                details.textContent = `${result.name} (Roll: ${result.rollNo}) - Confidence: ${result.confidence}%`;

                // Notify C# of match
                notifyCallback('match', {
                    name: result.name,
                    confidence: result.confidence,
                    isMatch: 'true',
                    hasImage: 'true'
                });
            } else {
                icon.textContent = 'âŒ';
                icon.className = 'result-icon result-no-match';
                text.textContent = 'NO MATCH';
                text.className = 'result-text result-no-match';
                details.textContent = result.name
                    ? `Closest: ${result.name} - Distance: ${result.distance.toFixed(3)} (Threshold: ${result.threshold})`
                    : 'No candidates to compare';

                // Notify C# of no match
                notifyCallback('notmatch', {
                    name: result.name || '',
                    confidence: result.confidence,
                    isMatch: 'false',
                    hasImage: 'true'
                });
            }

            overlay.classList.add('show');
        }

        function closeResult() {
            document.getElementById('resultOverlay').classList.remove('show');
            document.getElementById('captureBtn').disabled = false;
            updateStatus('Position your face in the circle', 'success');
            // Reset blink verification state
            matchedResult = null;
            resetBlinkState();
            // Restart the detection loop
            startDetectionLoop();
        }

        // ============================================================
        // UI HELPERS
        // ============================================================
        function updateStatus(message, type = '') {
            const status = document.getElementById('statusText');
            status.textContent = message;
            status.className = 'status-text' + (type ? ' ' + type : '');
        }

        // ============================================================
        // C# INTEROP (Callbacks via URL navigation)
        // ============================================================
        function notifyCallback(type, params) {
            const query = Object.entries(params)
                .map(([k, v]) => encodeURIComponent(k) + '=' + encodeURIComponent(v))
                .join('&');
            window.location.href = 'callback://' + type + '?' + query;
        }

        // Called from C# to register a reference image
        window.registerExternalImage = async function (base64Image, name) {
            try {
                updateStatus('Registering reference image...', 'warning');

                // Load and extract vector from the reference image
                const img = new Image();
                img.src = base64Image.startsWith('data:') ? base64Image : 'data:image/jpeg;base64,' + base64Image;
                await new Promise(resolve => { img.onload = resolve; });

                const detection = await faceapi
                    .detectSingleFace(img, new faceapi.SsdMobilenetv1Options({ minConfidence: CONFIG.MIN_CONFIDENCE }))
                    .withFaceLandmarks()
                    .withFaceDescriptor();

                if (detection) {
                    const vector = Array.from(detection.descriptor);

                    // Add to candidates
                    STORED_CANDIDATES.push({
                        RollNo: 'EXT001',
                        ApplicationNo: 'EXT001',
                        Name: name || 'External Reference',
                        FathersName: '',
                        Category: '',
                        Vector: vector
                    });

                    currentCandidate = STORED_CANDIDATES[STORED_CANDIDATES.length - 1];
                    document.getElementById('candidateInfo').textContent =
                        'Candidate: ' + currentCandidate.Name;

                    updateStatus('Reference registered. Position your face.', 'success');
                    return true;
                } else {
                    updateStatus('No face in reference image', 'error');
                    return false;
                }
            } catch (e) {
                updateStatus('Registration error: ' + e.message, 'error');
                return false;
            }
        };

        // Called from C# to get the last captured image
        window.getLastMatchImage = function () {
            return lastMatchImage;
        };

        // Called from C# to stop camera when leaving page
        window.stopCamera = function () {
            stopCamera();
        };

        // ============================================================
        // Initialize on load
        // ============================================================
        window.addEventListener('load', init);
    </script>
</body>

</html>